{"key":{"key":{"definition":{"m":1,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":136571},"median":{"secs":0,"nanos":117062},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":96574},"max":{"secs":0,"nanos":244755}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":249207},"median":{"secs":0,"nanos":229937},"variance":{"secs":0,"nanos":5},"min":{"secs":0,"nanos":178439},"max":{"secs":0,"nanos":471466}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":106591},"median":{"secs":0,"nanos":92025},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":79310},"max":{"secs":0,"nanos":215369}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":196153},"median":{"secs":0,"nanos":186494},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":162108},"max":{"secs":0,"nanos":293117}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":8,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":203922},"median":{"secs":0,"nanos":192736},"variance":{"secs":0,"nanos":7},"min":{"secs":0,"nanos":105420},"max":{"secs":0,"nanos":409868}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":225103},"median":{"secs":0,"nanos":212383},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":154023},"max":{"secs":0,"nanos":307324}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":8,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":206073},"median":{"secs":0,"nanos":181585},"variance":{"secs":0,"nanos":7},"min":{"secs":0,"nanos":117674},"max":{"secs":0,"nanos":383829}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":226004},"median":{"secs":0,"nanos":214458},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":183889},"max":{"secs":0,"nanos":345286}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":8,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":100769},"median":{"secs":0,"nanos":97254},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":78680},"max":{"secs":0,"nanos":158992}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":153616},"median":{"secs":0,"nanos":151247},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":108726},"max":{"secs":0,"nanos":280523}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":8,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":149453},"median":{"secs":0,"nanos":149855},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":97105},"max":{"secs":0,"nanos":223475}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":293756},"median":{"secs":0,"nanos":261877},"variance":{"secs":0,"nanos":8},"min":{"secs":0,"nanos":228424},"max":{"secs":0,"nanos":541479}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":8,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":115012},"median":{"secs":0,"nanos":107114},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":94480},"max":{"secs":0,"nanos":152380}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":300501},"median":{"secs":0,"nanos":290803},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":220819},"max":{"secs":0,"nanos":417673}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":164796},"median":{"secs":0,"nanos":165966},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":119287},"max":{"secs":0,"nanos":210170}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":301538},"median":{"secs":0,"nanos":274952},"variance":{"secs":0,"nanos":8},"min":{"secs":0,"nanos":218495},"max":{"secs":0,"nanos":485132}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":200498},"median":{"secs":0,"nanos":195351},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":168470},"max":{"secs":0,"nanos":243894}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":252750},"median":{"secs":0,"nanos":242190},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":199989},"max":{"secs":0,"nanos":374682}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":106322},"median":{"secs":0,"nanos":104479},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":87396},"max":{"secs":0,"nanos":137091}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":150585},"median":{"secs":0,"nanos":156237},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":131429},"max":{"secs":0,"nanos":177798}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":148816},"median":{"secs":0,"nanos":160505},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":103727},"max":{"secs":0,"nanos":188658}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":278165},"median":{"secs":0,"nanos":277267},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":216431},"max":{"secs":0,"nanos":354844}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":16,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":148466},"median":{"secs":0,"nanos":150356},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":121671},"max":{"secs":0,"nanos":202956}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":360818},"median":{"secs":0,"nanos":331009},"variance":{"secs":0,"nanos":6},"min":{"secs":0,"nanos":285011},"max":{"secs":0,"nanos":529897}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":171751},"median":{"secs":0,"nanos":160926},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":125218},"max":{"secs":0,"nanos":242180}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":246819},"median":{"secs":0,"nanos":243432},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":221180},"max":{"secs":0,"nanos":317603}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":169890},"median":{"secs":0,"nanos":148782},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":122984},"max":{"secs":0,"nanos":238874}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":230877},"median":{"secs":0,"nanos":234836},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":199069},"max":{"secs":0,"nanos":257699}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":97145},"median":{"secs":0,"nanos":98767},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":87476},"max":{"secs":0,"nanos":106112}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":151207},"median":{"secs":0,"nanos":154453},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":130087},"max":{"secs":0,"nanos":177867}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":170097},"median":{"secs":0,"nanos":171786},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":138704},"max":{"secs":0,"nanos":202184}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":321563},"median":{"secs":0,"nanos":285151},"variance":{"secs":0,"nanos":11},"min":{"secs":0,"nanos":229997},"max":{"secs":0,"nanos":610209}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":140500},"median":{"secs":0,"nanos":138172},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":111061},"max":{"secs":0,"nanos":173860}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":272493},"median":{"secs":0,"nanos":271055},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":228714},"max":{"secs":0,"nanos":312123}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":213414},"median":{"secs":0,"nanos":213726},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":169532},"max":{"secs":0,"nanos":255145}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":297015},"median":{"secs":0,"nanos":279351},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":239415},"max":{"secs":0,"nanos":406513}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":196085},"median":{"secs":0,"nanos":201012},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":139044},"max":{"secs":0,"nanos":244575}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":257458},"median":{"secs":0,"nanos":260565},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":232602},"max":{"secs":0,"nanos":290792}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":107485},"median":{"secs":0,"nanos":106553},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":97636},"max":{"secs":0,"nanos":126520}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":154142},"median":{"secs":0,"nanos":155075},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":132361},"max":{"secs":0,"nanos":180543}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":196784},"median":{"secs":0,"nanos":181796},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":138744},"max":{"secs":0,"nanos":257809}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":319626},"median":{"secs":0,"nanos":297055},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":252690},"max":{"secs":0,"nanos":397536}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":64,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":195572},"median":{"secs":0,"nanos":216932},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":137601},"max":{"secs":0,"nanos":236560}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":367375},"median":{"secs":0,"nanos":350225},"variance":{"secs":0,"nanos":3},"min":{"secs":0,"nanos":297745},"max":{"secs":0,"nanos":503567}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":204409},"median":{"secs":0,"nanos":202003},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":164683},"max":{"secs":0,"nanos":293969}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":281822},"median":{"secs":0,"nanos":286324},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":245446},"max":{"secs":0,"nanos":320319}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":220976},"median":{"secs":0,"nanos":188148},"variance":{"secs":0,"nanos":14},"min":{"secs":0,"nanos":136409},"max":{"secs":0,"nanos":574000}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":209023},"median":{"secs":0,"nanos":210760},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":185012},"max":{"secs":0,"nanos":233333}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":136520},"median":{"secs":0,"nanos":131309},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":116041},"max":{"secs":0,"nanos":157569}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":157534},"median":{"secs":0,"nanos":159984},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":141749},"max":{"secs":0,"nanos":176244}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":256,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":367252},"median":{"secs":0,"nanos":359513},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":308967},"max":{"secs":0,"nanos":442341}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":371500},"median":{"secs":0,"nanos":422703},"variance":{"secs":0,"nanos":9},"min":{"secs":0,"nanos":236078},"max":{"secs":0,"nanos":504569}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":256,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":371741},"median":{"secs":0,"nanos":371485},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":327693},"max":{"secs":0,"nanos":440467}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":328006},"median":{"secs":0,"nanos":386384},"variance":{"secs":0,"nanos":6},"min":{"secs":0,"nanos":236339},"max":{"secs":0,"nanos":432341}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":512,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":235391},"median":{"secs":0,"nanos":243803},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":203216},"max":{"secs":0,"nanos":256938}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":394523},"median":{"secs":0,"nanos":382507},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":361126},"max":{"secs":0,"nanos":466346}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":512,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":262195},"median":{"secs":0,"nanos":264773},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":214647},"max":{"secs":0,"nanos":318496}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":413627},"median":{"secs":0,"nanos":331049},"variance":{"secs":0,"nanos":27},"min":{"secs":0,"nanos":278569},"max":{"secs":0,"nanos":782547}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":512,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":148975},"median":{"secs":0,"nanos":145887},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":121271},"max":{"secs":0,"nanos":194309}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":158092},"median":{"secs":0,"nanos":151999},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":122833},"max":{"secs":0,"nanos":200491}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":512,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":498639},"median":{"secs":0,"nanos":415099},"variance":{"secs":0,"nanos":19},"min":{"secs":0,"nanos":390332},"max":{"secs":0,"nanos":723404}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":622477},"median":{"secs":0,"nanos":652489},"variance":{"secs":0,"nanos":6},"min":{"secs":0,"nanos":474551},"max":{"secs":0,"nanos":741840}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":512,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":460122},"median":{"secs":0,"nanos":398937},"variance":{"secs":0,"nanos":14},"min":{"secs":0,"nanos":375333},"max":{"secs":0,"nanos":701132}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":759905},"median":{"secs":0,"nanos":750696},"variance":{"secs":0,"nanos":3},"min":{"secs":0,"nanos":686083},"max":{"secs":0,"nanos":891303}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":233171},"median":{"secs":0,"nanos":229336},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":200291},"max":{"secs":0,"nanos":275384}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":323194},"median":{"secs":0,"nanos":319587},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":261907},"max":{"secs":0,"nanos":399489}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":204574},"median":{"secs":0,"nanos":200911},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":149073},"max":{"secs":0,"nanos":258110}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":239940},"median":{"secs":0,"nanos":241168},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":206362},"max":{"secs":0,"nanos":275293}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":114614},"median":{"secs":0,"nanos":113957},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":102064},"max":{"secs":0,"nanos":134235}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":148150},"median":{"secs":0,"nanos":150125},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":123494},"max":{"secs":0,"nanos":182777}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":128,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":268416},"median":{"secs":0,"nanos":298096},"variance":{"secs":0,"nanos":4},"min":{"secs":0,"nanos":179571},"max":{"secs":0,"nanos":346960}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":335423},"median":{"secs":0,"nanos":330178},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":288918},"max":{"secs":0,"nanos":389570}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":128,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":304129},"median":{"secs":0,"nanos":309638},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":201363},"max":{"secs":0,"nanos":344674}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":445126},"median":{"secs":0,"nanos":429666},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":418915},"max":{"secs":0,"nanos":544926}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1024,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":273509},"median":{"secs":0,"nanos":277367},"variance":{"secs":0,"nanos":10},"min":{"secs":0,"nanos":161466},"max":{"secs":0,"nanos":456606}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":583354},"median":{"secs":0,"nanos":512313},"variance":{"secs":0,"nanos":32},"min":{"secs":0,"nanos":460584},"max":{"secs":0,"nanos":1059001}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":1024,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":305379},"median":{"secs":0,"nanos":287967},"variance":{"secs":0,"nanos":6},"min":{"secs":0,"nanos":221792},"max":{"secs":0,"nanos":447760}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":414924},"median":{"secs":0,"nanos":471845},"variance":{"secs":0,"nanos":26},"min":{"secs":0,"nanos":235046},"max":{"secs":0,"nanos":697514}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":1024,"n":32,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":166865},"median":{"secs":0,"nanos":138172},"variance":{"secs":0,"nanos":4},"min":{"secs":0,"nanos":123294},"max":{"secs":0,"nanos":325558}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":291040},"median":{"secs":0,"nanos":275453},"variance":{"secs":0,"nanos":4},"min":{"secs":0,"nanos":190131},"max":{"secs":0,"nanos":401522}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":1024,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":968435},"median":{"secs":0,"nanos":1109517},"variance":{"secs":0,"nanos":98},"min":{"secs":0,"nanos":638652},"max":{"secs":0,"nanos":1571975}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":1048216},"median":{"secs":0,"nanos":1135766},"variance":{"secs":0,"nanos":155},"min":{"secs":0,"nanos":629895},"max":{"secs":0,"nanos":1696471}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":1024,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":3,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":986145},"median":{"secs":0,"nanos":1023122},"variance":{"secs":0,"nanos":91},"min":{"secs":0,"nanos":690942},"max":{"secs":0,"nanos":1609356}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":1057795},"median":{"secs":0,"nanos":1146396},"variance":{"secs":0,"nanos":55},"min":{"secs":0,"nanos":675663},"max":{"secs":0,"nanos":1349923}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":1,"n":32,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":101359},"median":{"secs":0,"nanos":87513},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":65530},"max":{"secs":0,"nanos":193092}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":173343},"median":{"secs":0,"nanos":163744},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":114807},"max":{"secs":0,"nanos":283971}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":32,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":69545},"median":{"secs":0,"nanos":65389},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":50540},"max":{"secs":0,"nanos":107733}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":91227},"median":{"secs":0,"nanos":81441},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":69557},"max":{"secs":0,"nanos":146540}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":77549},"median":{"secs":0,"nanos":64828},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":52303},"max":{"secs":0,"nanos":114386}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":199739},"median":{"secs":0,"nanos":183252},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":161048},"max":{"secs":0,"nanos":281286}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":1,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":101921},"median":{"secs":0,"nanos":72493},"variance":{"secs":0,"nanos":8},"min":{"secs":0,"nanos":60610},"max":{"secs":0,"nanos":367576}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":225043},"median":{"secs":0,"nanos":175417},"variance":{"secs":0,"nanos":24},"min":{"secs":0,"nanos":147692},"max":{"secs":0,"nanos":687679}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":64,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":105628},"median":{"secs":0,"nanos":86246},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":74112},"max":{"secs":0,"nanos":185667}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":173559},"median":{"secs":0,"nanos":155959},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":143606},"max":{"secs":0,"nanos":276631}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":64,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":87753},"median":{"secs":0,"nanos":92568},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":77389},"max":{"secs":0,"nanos":96094}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":173590},"median":{"secs":0,"nanos":176109},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":153274},"max":{"secs":0,"nanos":206727}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":100189},"median":{"secs":0,"nanos":91686},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":74053},"max":{"secs":0,"nanos":158674}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":159799},"median":{"secs":0,"nanos":163654},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":129509},"max":{"secs":0,"nanos":208511}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":150067},"median":{"secs":0,"nanos":146772},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":131743},"max":{"secs":0,"nanos":177220}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":192106},"median":{"secs":0,"nanos":155208},"variance":{"secs":0,"nanos":11},"min":{"secs":0,"nanos":130621},"max":{"secs":0,"nanos":501052}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":64,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":81066},"median":{"secs":0,"nanos":75916},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":63653},"max":{"secs":0,"nanos":130801}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":118076},"median":{"secs":0,"nanos":102296},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":69965},"max":{"secs":0,"nanos":202890}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":135766},"median":{"secs":0,"nanos":139759},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":91185},"max":{"secs":0,"nanos":200515}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":206206},"median":{"secs":0,"nanos":203490},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":172091},"max":{"secs":0,"nanos":300236}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":64,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":83846},"median":{"secs":0,"nanos":82819},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":68702},"max":{"secs":0,"nanos":114179}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":144059},"median":{"secs":0,"nanos":98919},"variance":{"secs":0,"nanos":13},"min":{"secs":0,"nanos":82278},"max":{"secs":0,"nanos":477467}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":64,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":88860},"median":{"secs":0,"nanos":79483},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":65817},"max":{"secs":0,"nanos":146662}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":204879},"median":{"secs":0,"nanos":190435},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":174345},"max":{"secs":0,"nanos":290538}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":32,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":74898},"median":{"secs":0,"nanos":73291},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":65897},"max":{"secs":0,"nanos":99891}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":88014},"median":{"secs":0,"nanos":87969},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":72639},"max":{"secs":0,"nanos":102447}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":64,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":68623},"median":{"secs":0,"nanos":67810},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":62220},"max":{"secs":0,"nanos":77619}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":184478},"median":{"secs":0,"nanos":185146},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":156891},"max":{"secs":0,"nanos":238228}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":139427},"median":{"secs":0,"nanos":137344},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":121694},"max":{"secs":0,"nanos":161100}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":147552},"median":{"secs":0,"nanos":146772},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":125831},"max":{"secs":0,"nanos":169284}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":64,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":77206},"median":{"secs":0,"nanos":72309},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":63702},"max":{"secs":0,"nanos":124208}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":95876},"median":{"secs":0,"nanos":93009},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":78210},"max":{"secs":0,"nanos":130941}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":141030},"median":{"secs":0,"nanos":141511},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":119339},"max":{"secs":0,"nanos":158524}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":191347},"median":{"secs":0,"nanos":186508},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":172111},"max":{"secs":0,"nanos":236975}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":113298},"median":{"secs":0,"nanos":94619},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":73969},"max":{"secs":0,"nanos":256164}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":192656},"median":{"secs":0,"nanos":182084},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":143220},"max":{"secs":0,"nanos":286971}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":64,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":103267},"median":{"secs":0,"nanos":95360},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":72156},"max":{"secs":0,"nanos":186783}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":173812},"median":{"secs":0,"nanos":159521},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":144903},"max":{"secs":0,"nanos":250212}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":32,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":93908},"median":{"secs":0,"nanos":94959},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":79119},"max":{"secs":0,"nanos":116941}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":174354},"median":{"secs":0,"nanos":173818},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":156736},"max":{"secs":0,"nanos":200108}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":77434},"median":{"secs":0,"nanos":75482},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":71766},"max":{"secs":0,"nanos":89338}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":149352},"median":{"secs":0,"nanos":146005},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":127411},"max":{"secs":0,"nanos":202251}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":137309},"median":{"secs":0,"nanos":122170},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":104457},"max":{"secs":0,"nanos":239532}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":191923},"median":{"secs":0,"nanos":174379},"variance":{"secs":0,"nanos":3},"min":{"secs":0,"nanos":136938},"max":{"secs":0,"nanos":304264}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":90588},"median":{"secs":0,"nanos":90000},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":73879},"max":{"secs":0,"nanos":112442}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":142782},"median":{"secs":0,"nanos":141738},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":113825},"max":{"secs":0,"nanos":173518}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":72990},"median":{"secs":0,"nanos":60514},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":53742},"max":{"secs":0,"nanos":114647}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":110563},"median":{"secs":0,"nanos":92134},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":69140},"max":{"secs":0,"nanos":237448}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":4,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":147161},"median":{"secs":0,"nanos":134794},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":102834},"max":{"secs":0,"nanos":256113}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":191448},"median":{"secs":0,"nanos":188256},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":150725},"max":{"secs":0,"nanos":239883}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":32,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":94132},"median":{"secs":0,"nanos":88397},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":59372},"max":{"secs":0,"nanos":169890}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":101265},"median":{"secs":0,"nanos":90431},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":80602},"max":{"secs":0,"nanos":176072}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":110257},"median":{"secs":0,"nanos":106191},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":95140},"max":{"secs":0,"nanos":140716}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":211060},"median":{"secs":0,"nanos":191100},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":163379},"max":{"secs":0,"nanos":339120}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":64,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":82315},"median":{"secs":0,"nanos":72337},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":65103},"max":{"secs":0,"nanos":133662}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":95926},"median":{"secs":0,"nanos":75934},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":68178},"max":{"secs":0,"nanos":185280}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":32,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":61506},"median":{"secs":0,"nanos":63409},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":54002},"max":{"secs":0,"nanos":69461}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":201318},"median":{"secs":0,"nanos":186261},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":160072},"max":{"secs":0,"nanos":292943}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":16,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":65708},"median":{"secs":0,"nanos":63870},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":57048},"max":{"secs":0,"nanos":83017}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":97751},"median":{"secs":0,"nanos":88928},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":74631},"max":{"secs":0,"nanos":177084}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":64,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":78368},"median":{"secs":0,"nanos":78749},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":56327},"max":{"secs":0,"nanos":158479}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":177722},"median":{"secs":0,"nanos":177475},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":145194},"max":{"secs":0,"nanos":236175}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":1,"n":32,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"VecMat"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":79302},"median":{"secs":0,"nanos":69551},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":58180},"max":{"secs":0,"nanos":138972}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":71714},"median":{"secs":0,"nanos":71935},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":59042},"max":{"secs":0,"nanos":90661}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":1,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"OuterProduct"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":73348},"median":{"secs":0,"nanos":66305},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":55425},"max":{"secs":0,"nanos":137640}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":168938},"median":{"secs":0,"nanos":165052},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":115358},"max":{"secs":0,"nanos":230284}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":155192},"median":{"secs":0,"nanos":147368},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":132530},"max":{"secs":0,"nanos":227950}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":175793},"median":{"secs":0,"nanos":179048},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":140566},"max":{"secs":0,"nanos":211319}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":94412},"median":{"secs":0,"nanos":93226},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":83277},"max":{"secs":0,"nanos":114446}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":146194},"median":{"secs":0,"nanos":142689},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":114156},"max":{"secs":0,"nanos":194597}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":16,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":77173},"median":{"secs":0,"nanos":75973},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":61386},"max":{"secs":0,"nanos":107273}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":89227},"median":{"secs":0,"nanos":88226},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":75503},"max":{"secs":0,"nanos":107363}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":4,"k":128,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":153453},"median":{"secs":0,"nanos":155163},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":141567},"max":{"secs":0,"nanos":170792}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":191597},"median":{"secs":0,"nanos":206590},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":155413},"max":{"secs":0,"nanos":212912}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":128,"n":32,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":97371},"median":{"secs":0,"nanos":78558},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":70774},"max":{"secs":0,"nanos":168188}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":93961},"median":{"secs":0,"nanos":97193},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":80161},"max":{"secs":0,"nanos":112152}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":128,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":152736},"median":{"secs":0,"nanos":149032},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":137119},"max":{"secs":0,"nanos":191471}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":245553},"median":{"secs":0,"nanos":238851},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":220376},"max":{"secs":0,"nanos":286440}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":115902},"median":{"secs":0,"nanos":110629},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":105439},"max":{"secs":0,"nanos":151125}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":164134},"median":{"secs":0,"nanos":153520},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":121880},"max":{"secs":0,"nanos":291601}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":97006},"median":{"secs":0,"nanos":98345},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":77266},"max":{"secs":0,"nanos":126549}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":140768},"median":{"secs":0,"nanos":139904},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":121910},"max":{"secs":0,"nanos":175311}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":16,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":79909},"median":{"secs":0,"nanos":64712},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":59091},"max":{"secs":0,"nanos":143872}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":99474},"median":{"secs":0,"nanos":89419},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":74320},"max":{"secs":0,"nanos":202091}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":4,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":124521},"median":{"secs":0,"nanos":120647},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":106802},"max":{"secs":0,"nanos":152979}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":176854},"median":{"secs":0,"nanos":172626},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":153099},"max":{"secs":0,"nanos":233341}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":64,"n":32,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":90538},"median":{"secs":0,"nanos":72937},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":61747},"max":{"secs":0,"nanos":150705}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":100153},"median":{"secs":0,"nanos":98847},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":86543},"max":{"secs":0,"nanos":114095}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":64,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":123785},"median":{"secs":0,"nanos":127590},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":108464},"max":{"secs":0,"nanos":134934}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":213623},"median":{"secs":0,"nanos":208924},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":187845},"max":{"secs":0,"nanos":271122}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":149806},"median":{"secs":0,"nanos":139122},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":119024},"max":{"secs":0,"nanos":200177}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":165429},"median":{"secs":0,"nanos":169109},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":133391},"max":{"secs":0,"nanos":194527}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":107825},"median":{"secs":0,"nanos":106531},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":100289},"max":{"secs":0,"nanos":118022}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":155636},"median":{"secs":0,"nanos":158248},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":132009},"max":{"secs":0,"nanos":177775}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":16,"k":4,"lhs_pow2_factor":2,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":90539},"median":{"secs":0,"nanos":84389},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":67237},"max":{"secs":0,"nanos":150074}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":102468},"median":{"secs":0,"nanos":101221},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":91462},"max":{"secs":0,"nanos":114416}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":16,"n":4,"k":256,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":203400},"median":{"secs":0,"nanos":206821},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":177094},"max":{"secs":0,"nanos":227971}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":234210},"median":{"secs":0,"nanos":225946},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":196421},"max":{"secs":0,"nanos":282894}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":256,"n":32,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}}},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":93340},"median":{"secs":0,"nanos":90962},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":80572},"max":{"secs":0,"nanos":115337}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":121007},"median":{"secs":0,"nanos":98446},"variance":{"secs":0,"nanos":2},"min":{"secs":0,"nanos":82866},"max":{"secs":0,"nanos":216479}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":32,"n":16,"k":256,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":{"MildlyPermuted":{"transposed":true,"batch_swap":false}},"matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Small","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":201206},"median":{"secs":0,"nanos":198024},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":190109},"max":{"secs":0,"nanos":220516}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::naive<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":0,"computation":{"mean":{"secs":0,"nanos":246278},"median":{"secs":0,"nanos":243048},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":215366},"max":{"secs":0,"nanos":280369}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":"Skip"},{"Err":"Skip"}]}}
{"key":{"key":{"definition":{"m":2048,"n":32,"k":32,"lhs_pow2_factor":2,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":224108},"median":{"secs":0,"nanos":205327},"variance":{"secs":0,"nanos":6},"min":{"secs":0,"nanos":159731},"max":{"secs":0,"nanos":409904}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":349280},"median":{"secs":0,"nanos":352194},"variance":{"secs":0,"nanos":16},"min":{"secs":0,"nanos":185951},"max":{"secs":0,"nanos":653794}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":2048,"n":16,"k":32,"lhs_pow2_factor":3,"rhs_pow2_factor":3,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":256164},"median":{"secs":0,"nanos":211920},"variance":{"secs":0,"nanos":4},"min":{"secs":0,"nanos":188225},"max":{"secs":0,"nanos":365750}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":304539},"median":{"secs":0,"nanos":251124},"variance":{"secs":0,"nanos":12},"min":{"secs":0,"nanos":203374},"max":{"secs":0,"nanos":524410}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
{"key":{"key":{"definition":{"m":2048,"n":4,"k":16,"lhs_pow2_factor":3,"rhs_pow2_factor":2,"elem_lhs":{"Float":"F32"},"elem_rhs":{"Float":"F32"},"elem_out":{"Float":"F32"},"matrix_layout_lhs":"Contiguous","matrix_layout_rhs":"Contiguous"},"analysis":{"scale_global":"Medium","kind":"General"}},"checksum":"5ad9018f72c752b3aff5488ebcd72c6c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::simple_unit_max<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":2,"computation":{"mean":{"secs":0,"nanos":180446},"median":{"secs":0,"nanos":175792},"variance":{"secs":0,"nanos":1},"min":{"secs":0,"nanos":129004},"max":{"secs":0,"nanos":254170}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::matmul::tune::base::double_unit<cubecl_wgpu::runtime::WgpuRuntime, f32>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>) -> core::result::Result<(), alloc::string::String>>","index":3,"computation":{"mean":{"secs":0,"nanos":189588},"median":{"secs":0,"nanos":191351},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":159551},"max":{"secs":0,"nanos":231778}}}},{"Err":"Skip"},{"Err":"Skip"},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on inputs Float(F32) and outputs Float(F32) with shape m=16, n=16, k=8 not supported.\n\n"}}]}}
